{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de42e95c",
   "metadata": {},
   "source": [
    "#### This contains the learning from Documentation\n",
    "```bash\n",
    "pip install beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71bc23",
   "metadata": {},
   "source": [
    "#### BeautifulSoup have 4 types of Objects\n",
    "- Tag : which itself is a HTML or XML tag\n",
    "- BeautifulSoup \n",
    "- NavigableString : these are the texts\n",
    "- Comment : this contains the HTML comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_text = '''\n",
    "<html>\n",
    "<head>\n",
    "<title>Demo Webscrapping</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Web Scraping Example</h1>\n",
    "<p>This is a simple example of web scraping using Python.</p>\n",
    "<p>Web scraping is the process of extracting data from websites.</p>\n",
    "<p class=\"important\">Important: Always check the website's terms of service before scraping.</p>\n",
    "<p class=\"note\">Note: This example is for educational purposes only.</p>\n",
    "<p>For more information, visit <a href=\"https://www.example.com\">Example Website</a>.</p>\n",
    "<p>Follow us on <a href=\"https://twitter.com/example\">Twitter</a> for updates.</p>\n",
    "<div class=\"footer\">\n",
    "<p>&copy; 2023 Web Scraping Inc.</p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8516c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "title\n",
      "Demo Webscrapping\n",
      "{}\n",
      "{'class': ['important']}\n",
      "dict_keys(['class'])\n",
      "dict_values([['important']])\n",
      "['important']\n",
      "['important']\n",
      "No id attribute\n",
      "<p class=\"important\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
      "<p class=\"critical\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
      "['critical', 'urgent']\n",
      "<p class=\"critical urgent\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
      "<p class=\"critical urgent\">Important: Always check the website's terms of service before scraping.</p>\n",
      "['critical', 'urgent']\n",
      "['critical', 'urgent']\n"
     ]
    }
   ],
   "source": [
    "# Tag\n",
    "soup = BeautifulSoup(html_text, 'html.parser')  # multi_valued_attributes = None  # to get the attributes as a list, otherwise it will be a string\n",
    "tag = soup.title\n",
    "print(type(tag))  # <class 'bs4.element.Tag'>\n",
    "print(tag.name)  # title\n",
    "print(tag.string)  # Demo Webscrapping, the text inside the title tag is a type of NavigableString\n",
    "print(tag.attrs)  # {}\n",
    "tag = soup.find('p', class_='important')\n",
    "print(tag.attrs) # all attributes of the tag\n",
    "print(tag.attrs.keys())  # keys of the attributes\n",
    "print(tag.attrs.values())  # values of the attributes\n",
    "print(tag['class'])  # important, accessing the class attribute directly\n",
    "print(tag.get('class'))  # important, using get method to access the class attribute\n",
    "print(tag.get('id', 'No id attribute'))  # No id attribute, using get method with default value\n",
    "tag['id'] = 'important-paragraph'  # adding a new attribute\n",
    "print(tag)  # <p class=\"important\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
    "tag['class'] = 'critical'  # modifying an existing attribute\n",
    "print(tag)  # <p class=\"critical\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
    "tag.attrs['class'] = ['critical', 'urgent']# appending a new class to the existing class attribute\n",
    "print(tag.attrs['class'])  # <p class=\"critical urgent\" id=\"important-paragraph\">Important: Always check the website's terms of service before scraping.</p>\n",
    "print(tag)\n",
    "del tag['id']  # deleting an attribute\n",
    "print(tag)  # <p class=\"critical urgent\">Important: Always check the website's terms of service before scraping.</p>\n",
    "print(tag.attrs['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013367d8",
   "metadata": {},
   "source": [
    "#### For xml \n",
    "class_is_multi= { '*' : 'class'}\n",
    "xml_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'xml', multi_valued_attributes=class_is_multi)\n",
    "xml_soup.p['class']\n",
    "- Output -> ['body', 'strikeout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3f70448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n",
      "Hello World\n",
      "Hello Python\n",
      "HELLO WORLD\n",
      "<p>New Text</p>\n",
      "Replaced Text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWe can also use the `stripped_strings` generator to get all the strings in the tag without leading or trailing whitespace.\\nfor string in soup.p.stripped_strings:\\n    print(string)  # New Text   \\n\\nWe can not use .string on a Tag object that contains other tags, as it will return None.\\n# If we try to access the string of a tag that contains other tags, it will return None.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NavigableString\n",
    "soup = BeautifulSoup('<p>Hello World</p>', 'html.parser')\n",
    "# soup = BeautifulSoup('<p>Hello World <a> this is link</a></p>', 'html.parser')\n",
    "\n",
    "print(type(soup.p.string))  # <class 'bs4.element.NavigableString'>\n",
    "print(soup.p.string)  # Hello World\n",
    "print(soup.p.string.replace('World', 'Python'))  # Hello Python\n",
    "print(soup.p.string.upper())  # HELLO WORLD\n",
    "soup.p.string = 'New Text'  # modifying the NavigableString\n",
    "print(soup.p)  # <p>New Text</p>\n",
    "soup.p.string.replace_with('Replaced Text')  # replacing the NavigableString with a new string\n",
    "print(soup.p.string)\n",
    "# print(soup.p.contents)  # this will give you a list of all the children of the p tag, including NavigableString and Tag objects\n",
    "\n",
    "'''\n",
    "We can also use the `stripped_strings` generator to get all the strings in the tag without leading or trailing whitespace.\n",
    "for string in soup.p.stripped_strings:\n",
    "    print(string)  # New Text   \n",
    "\n",
    "We can not use .string on a Tag object that contains other tags, as it will return None.\n",
    "# If we try to access the string of a tag that contains other tags, it will return None.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<document><content/><footer>Here's the footer</footer></document>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18826/3937926054.py:4: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  doc.find(text=\"INSERT FOOTER HERE\").replace_with(footer)\n"
     ]
    }
   ],
   "source": [
    "# NavigableString\n",
    "doc = BeautifulSoup(\"<document><content/>INSERT FOOTER HERE</document\", \"xml\")\n",
    "footer = BeautifulSoup(\"<footer>Here's the footer</footer>\", \"xml\")\n",
    "doc.find(text=\"INSERT FOOTER HERE\").replace_with(footer)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7b6e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, buddy. Want to buy a used parser?\n",
      "<b>\n",
      " <!--Hey, buddy. Want to buy a used parser?-->\n",
      "</b>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comment\n",
    "markup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\n",
    "soup = BeautifulSoup(markup, 'html.parser')\n",
    "comment = soup.b.string\n",
    "type(comment)\n",
    "print(comment)\n",
    "print(soup.b.prettify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
